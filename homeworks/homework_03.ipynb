{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "1. Draw the Bayesian Network representing the joint distribution\n",
    "\n",
    "$$P(A,B,C,D,E,F,G,H)=P(A)P(B|A)P(C)P(D|B)P(E)P(F|A)P(G|D,F)P(H|E,B).$$\n",
    "\n",
    "![Network](homework_03_Bayes_Network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By considering, two nodes $A$ and $B$ in a directed graph are **conditionally independent** given a node $C$  if and only if \n",
    "\n",
    "$$p(A,B|C)=p(A|C)p(B|C).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Indicate whether the following statements on conditional independence are True or False and motivate your answer.\n",
    "\n",
    " a. $A\\perp \\!\\!\\! \\perp  B$\n",
    " * False, it is obvious that A and B are not conditionally independent and $P(A,B) = P(A).P(B|A)$\n",
    " \n",
    " b. $A \\perp \\!\\!\\! \\perp  C$\n",
    " * True, A and C has no relation and $P(A,C) = P(A)P(C)$\n",
    " \n",
    " c. $A\\perp \\!\\!\\! \\perp  D | \\{B, H\\}$\n",
    " * True, because $P(A,B,C,D) = P(A)P(D|B)P(B|A)P(H)$ imply that $P(A| \\{B, H\\})P(D| \\{B, H\\})$\n",
    " \n",
    " d. $A\\perp \\!\\!\\! \\perp  E | F$\n",
    " * True, because $P(A,E,F) = P(A)P(E)P(F|A)$ implies that $P(A,E|F) = P(A|F)P(E|F)$ \n",
    " \n",
    " e. $G\\perp \\!\\!\\! \\perp  E | B$\n",
    " * True, because $P(G,E,B) = P(G)P(B)P(E)$\n",
    " \n",
    " f. $F\\perp \\!\\!\\! \\perp C| D$\n",
    " * True, because $P(F,C,D) = P(F)P(C)P(D)$\n",
    " \n",
    " g. $E\\perp \\!\\!\\! \\perp  D | B$\n",
    " * True, becasue $P(E,D,B) = P(E)P(D|B)P(B)$ implies that $P(E,D|B) = P(E|B)P(D|B)$\n",
    " \n",
    " h. $C\\perp \\!\\!\\! \\perp  H | G$\n",
    " * True, because $P(C,H,G) = P(C)P(H)P(G)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "* Build the generative model corresponding to the directed graph\n",
    "\n",
    "![image.png](homework_03_image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generative model**\n",
    "\n",
    "- $\\theta \\sim Dirichlet(\\alpha)$\n",
    "- $\\mu_k \\sim \\mathcal{N}(0,\\eta^2)$ for the mixture components\n",
    "- for each data point $t$:\n",
    " - $z_0 | \\theta \\sim Categorical(\\theta)$\n",
    " - $z_{t} | \\theta, z_{t-1} \\sim Categorical(\\theta,z_{t-1})$\n",
    " - $x_t|z_t,\\mu_{k_t} \\sim \\mathcal{N}(\\mu_{k_t},1)$\n",
    " \n",
    "where $\\theta, \\mu_k, z_t$ are the **hidden variables**, $x_i$ the **observables** and $\\alpha, \\eta$ the fixed **hyperparameters**.\n",
    "  \n",
    "The joint distribution factorizes as:\n",
    "$$\n",
    "p(\\theta,\\mu,z,x|\\eta,\\alpha) = \\prod_{k=1}^K p(\\theta_t|\\alpha) p(\\mu_k|\\eta)\\prod_{i=1}^N[p(z_t|\\theta,z_{t-1})p(x_t|z_t,\\mu_k)].\n",
    "$$\n",
    "\n",
    "where $N$ is the number of observation and $z_0 \\sim Categorical(\\theta)$ , ($\\theta$ chosen uniformly)\n",
    "\n",
    "From this we can define the posterior distribution as:\n",
    "$$\n",
    "p(\\theta,\\mu,z|x,\\eta,\\alpha)=\\frac{p(\\theta,\\mu,z,x|\\eta,\\alpha)}{p(x|\\eta,\\alpha)}.\n",
    "$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using Dirichlet, Categorical and Normal distributions and supposing that $K=2$. Then, write a `pyro` implementation of the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta = tensor([[0.5044, 0.4956],\n",
      "        [0.9974, 0.0026]]) \n",
      "mu = tensor([ 2.6518, -9.0638]) \n",
      "z = tensor([0, 1, 0, 1, 0, 1]) \n",
      "x = [5.3, 2.4, 3.5, 6.1, 1.2, 2.6]\n"
     ]
    }
   ],
   "source": [
    "import pyro\n",
    "import torch\n",
    "import pyro.distributions as dist\n",
    "import random as rnd\n",
    "\n",
    "# Number of components\n",
    "K = 2\n",
    "\n",
    "#Hyperparameters\n",
    "\n",
    "alpha = 0.7\n",
    "eta = 5\n",
    "idx = rnd.randint(0,1) # random index that will help to sample first z (z_f) to choose theta parameter uniformly\n",
    "\n",
    "def model(data):\n",
    "    N = len(data)\n",
    "    \n",
    "    with pyro.plate('hidden_variable', K):\n",
    "        theta = pyro.sample('theta', dist.Dirichlet(alpha * torch.ones(K)))\n",
    "    \n",
    "    with pyro.plate('components', K):\n",
    "        mu = pyro.sample(\"mu\", dist.Normal(0., eta))\n",
    "\n",
    "    # list that will be used for storing z values    \n",
    "    z = list()\n",
    "    for i in pyro.plate(\"data\", N):\n",
    "        if i == 0:\n",
    "            # first z, so theta parameter is chosen uniformly\n",
    "            z_f = pyro.sample(\"z\",dist.Categorical(probs = theta[idx]))\n",
    "            z.append(z_f)\n",
    "        else:\n",
    "            # z_r which depends on previous z values (z_f)\n",
    "            z_r = pyro.sample('z', dist.Categorical(probs = theta[z_f]))\n",
    "            z.append(z_r)\n",
    "            \n",
    "            # z_f are updated to make z dependent to previous ones\n",
    "            z_f = z_r\n",
    "        \n",
    "        # sampling x, dependent to z and mu\n",
    "        x = pyro.sample(\"x\", dist.Normal(mu[z_f],1),obs= data)\n",
    "    # bringing all z's to one place        \n",
    "    z = torch.stack(tuple(z),0)\n",
    "    \n",
    "    print(\"theta =\",theta,\"\\nmu =\",mu,\"\\nz =\", z,\"\\nx =\",  x)\n",
    "    \n",
    "    \n",
    "model(data = [5.3,2.4,3.5,6.1,1.2,2.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "data = [1,2,3,4]\n",
    "for i in range(len(data)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
